{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69c7ffef",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from notebook import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89a0975b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Copie les notebooks et supprime les sorties.\n",
    "# # Décommenter et exécuter cette cellule avant de commiter/pusher\n",
    "# # les modifications du notebook sur Github.\n",
    "# copy_and_clean_notebooks()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047f17f2",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Ce notebook va nous permettre de mettre à jour le jeu de données de LUIS et de mettre à jour les paramètres de LUIS en conséquence. Nous allons notamment ajouter dans le jeu de données les textes extraits des analyses d'insatisfactions.\n",
    "\n",
    "<img src=\"./data/img/archi_update_luis.png\" alt=\"Mise à jour de LUIS\" width=\"700\"/>\n",
    "<p style=\"text-align: center; text-decoration: underline;\">Mise à jour de LUIS</p>\n",
    "\n",
    "Attention de ne pas exécuter ce notebook après chaque analyse des insatisfactions. D'après la documentation de LUIS ([en savoir plus](https://docs.microsoft.com/en-us/azure/cognitive-services/luis/luis-concept-best-practices#dont-train-and-publish-with-every-single-example-utterance)), il est recommendé d'avoir au moins 15 nouveaux textes à ajouter au jeu de données pour observer des améliorations du modèle."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d57a3b1",
   "metadata": {},
   "source": [
    "# Création d'une nouvelle branche git\n",
    "\n",
    "Commencer par créer une nouvelle branche git pour effectuer et tester vos modifications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3367f80",
   "metadata": {},
   "source": [
    "# Chargement des ressources\n",
    "\n",
    "Nous allons charger toutes les ressources Azure qui vont nous permettre de créer et d'enregistrer des jeux de données.\n",
    "\n",
    "Nous allons aussi charger les paramètres du modèle LUIS actuel."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cab4bcd",
   "metadata": {},
   "source": [
    "## Chargement du workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27df5ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On charge l’espace de travail Azure Machine Learning existant\n",
    "ws = Workspace.from_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833dfc16",
   "metadata": {},
   "source": [
    "## Chargement du magasin des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c3e09e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On charge le magasin de données par défaut\n",
    "datastore = ws.get_default_datastore()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d77bf90",
   "metadata": {},
   "source": [
    "## Chargement des paramètres de LUIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "192ce075",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On charge les variables d'environnement de LUIS\n",
    "env = LUISEnv(\"../P10_02_luis/.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "452e36b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On charge les paramètres du modèle\n",
    "with open(\"../P10_02_luis/params.json\") as f:\n",
    "    params = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61986cb",
   "metadata": {},
   "source": [
    "# Mise à jour du jeu de données\n",
    "\n",
    "Dans cette partie, nous allons labelliser de nouvelles données et les ajouter au jeu de données existant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa0e218",
   "metadata": {},
   "source": [
    "## Chargement des textes à labelliser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29790bce",
   "metadata": {},
   "source": [
    "### Intent `book_flight`\n",
    "\n",
    "Copier dans la liste ci-dessous les textes ayant pour intent `book_flight` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "236fcbf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# On colle les nouveaux textes à labelliser\n",
    "book_flight_texts = [\n",
    "    \"Book me a flight from London to Paris tomorrow. I have only 100€.\"\n",
    "]\n",
    "\n",
    "len(book_flight_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2bd46c2",
   "metadata": {},
   "source": [
    "### Intent `None`\n",
    "\n",
    "Copier dans la liste ci-dessous les textes ayant pour intent `None` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "036fb2f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# On colle les nouveaux textes à labelliser\n",
    "none_texts = [\n",
    "    \"Hey !!!\"\n",
    "]\n",
    "\n",
    "len(none_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef68a943",
   "metadata": {},
   "source": [
    "## Chargement du précédent jeu de données\n",
    "\n",
    "On va récupérer le jeu d'entrainement et le jeu de test du dataset utilisé pour entrainer le modèle actuel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7f2f7d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On récupère les information du dataset\n",
    "ds_name = params[\"dataset\"][\"name\"]\n",
    "ds_version = params[\"dataset\"][\"version\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ab5be7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tempfile.TemporaryDirectory() as tmp_dir_name:\n",
    "    dataset = Dataset.get_by_name(ws, **params[\"dataset\"])\n",
    "    dataset.download(target_path=tmp_dir_name, overwrite=False)\n",
    "\n",
    "    # On charge le jeu d'entrainement\n",
    "    file_path = os.path.join(tmp_dir_name, \"utterances_train.json\")\n",
    "    with open(file_path) as f:\n",
    "        utterances_train = json.load(f)\n",
    "\n",
    "    # On charge le jeu de test\n",
    "    file_path = os.path.join(tmp_dir_name, \"utterances_test.json\")\n",
    "    with open(file_path) as f:\n",
    "        utterances_test = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe9e796",
   "metadata": {},
   "source": [
    "## Suppression des doublons\n",
    "\n",
    "On va extraire les textes de ces jeux de données afin de supprimer les doublons dans les nouveaux textes à labelliser :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aa3e0b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraction des textes du jeu de données pour l'intent \"book_flight\"\n",
    "old_texts = get_texts_from_dataset(\n",
    "    utterances_train,\n",
    "    utterances_test,\n",
    "    \"book_flight\"\n",
    ")\n",
    "\n",
    "# Extraction des textes du jeu de données pour l'intent \"None\"\n",
    "old_texts += get_texts_from_dataset(\n",
    "    utterances_train,\n",
    "    utterances_test,\n",
    "    \"None\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5cdea6",
   "metadata": {},
   "source": [
    "### Intent `book_flight`\n",
    "\n",
    "On supprime les doublons pour l'intent `book_flight`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "57731fd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# On supprime les doublons\n",
    "book_flight_texts = [i for i in book_flight_texts if i not in old_texts]\n",
    "\n",
    "len(book_flight_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d90280a",
   "metadata": {},
   "source": [
    "### Intent `None`\n",
    "\n",
    "On supprime les doublons pour l'intent `None`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4cc66a77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# On supprime les doublons\n",
    "none_texts = [i for i in none_texts if i not in old_texts]\n",
    "\n",
    "len(none_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac40b97",
   "metadata": {},
   "source": [
    "## Transformation des données\n",
    "\n",
    "Nous allons maintenant convertir nos textes pour les mettre au format LUIS."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acdb1f7e",
   "metadata": {},
   "source": [
    "### Intent `book_flight`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5112870f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On convertit les textes au format LUIS\n",
    "new_utterances = texts_to_luis_utterances(book_flight_texts, \"book_flight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba44514",
   "metadata": {},
   "source": [
    "### Intent `None`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "669fb68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On convertit les textes au format LUIS\n",
    "new_utterances += texts_to_luis_utterances(none_texts, \"None\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17193ae7",
   "metadata": {},
   "source": [
    "## Labellisation des nouveaux textes\n",
    "\n",
    "Afin de labelliser les nouveaux textes, nous allons utiliser l'outil de labellisation de LUIS Portal ([en savoir plus](https://docs.microsoft.com/en-us/azure/cognitive-services/luis/sign-in-luis-portal))."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f9d563d",
   "metadata": {},
   "source": [
    "### Création d'un modèle LUIS pour la labellisation\n",
    "\n",
    "Nous allons commencer par créer une version du modèle actuel sans aucun texte :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "22637f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nom de version spécial pour la labellisation\n",
    "labellisation_app_version = \"labellisation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e8973268",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On crée la nouvelle version\n",
    "create_new_version(env, labellisation_app_version, params[\"model\"], new_utterances)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717e18b9",
   "metadata": {},
   "source": [
    "### Labellisation manuelle\n",
    "\n",
    "La labellisation des nouveaux textes doit se faire manuellement ([en savoir plus](https://docs.microsoft.com/en-us/azure/cognitive-services/luis/label-entity-example-utterance)) :\n",
    "- Aller sur LUIS Portal.\n",
    "- Dans la section `MANAGE/Versions` sélectionner la version `labellisation` et cliquer sur `Activate` pour l'activer.\n",
    "- Aller ensuite dans la section `BUILD/Intents` et sélectionner l'intent `book_flight`.\n",
    "- Labelliser les textes de l'intent en sélectionnant les entities et en leur attribuant un label.\n",
    "\n",
    "<img src=\"./data/img/data_labellisation.png\" alt=\"Exemple de labellisation d'une phrase sur LUIS Portal\" width=\"700\"/>\n",
    "<p style=\"text-align: center; text-decoration: underline;\">Exemple de labellisation d'une phrase sur LUIS Portal</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0760d58e",
   "metadata": {},
   "source": [
    "### Téléchargement des utterances labellisées\n",
    "\n",
    "Une fois les textes labellisés sur LUIS Portal, il nous suffit de les télécharger :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f039721f",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_utterances = get_utterances(env, labellisation_app_version)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7733daa6",
   "metadata": {},
   "source": [
    "Observons la première donnée afin de vérifier que la labellisation a bien été effectuée :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "908cfbe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"text\": \"book me a flight from london to paris tomorrow. i have only 100\\u20ac.\",\n",
      "  \"intent\": \"book_flight\",\n",
      "  \"entities\": [\n",
      "    {\n",
      "      \"entity\": \"from_city\",\n",
      "      \"startPos\": 22,\n",
      "      \"endPos\": 27,\n",
      "      \"children\": []\n",
      "    },\n",
      "    {\n",
      "      \"entity\": \"to_city\",\n",
      "      \"startPos\": 32,\n",
      "      \"endPos\": 36,\n",
      "      \"children\": []\n",
      "    },\n",
      "    {\n",
      "      \"entity\": \"from_dt\",\n",
      "      \"startPos\": 38,\n",
      "      \"endPos\": 45,\n",
      "      \"children\": []\n",
      "    },\n",
      "    {\n",
      "      \"entity\": \"budget\",\n",
      "      \"startPos\": 60,\n",
      "      \"endPos\": 63,\n",
      "      \"children\": []\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "pprint_dict(new_utterances[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cef55cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On ssuprime la version temporaire de labellisation\n",
    "delete(env, labellisation_app_version)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ae3c98",
   "metadata": {},
   "source": [
    "## Split des données\n",
    "\n",
    "Nous allons séparer nos données en un jeu d'entrainement et un jeu de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ba4435d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On va prendre 70% des données pour le jeu d'entrainement\n",
    "train_nb = int(len(new_utterances) * 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e6c514fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On mélanges les utterances\n",
    "random.shuffle(new_utterances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5ffac64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On crée le jeu d'entrainement\n",
    "new_utterances_train = new_utterances[:train_nb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4d4cfa68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On crée le jeu de test\n",
    "new_utterances_test = new_utterances[train_nb:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af93ff52",
   "metadata": {},
   "source": [
    "## Ajout des précédentes utterances\n",
    "\n",
    "On ajoute les nouveaux textes labellisés au précédents jeux de données :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "eeb845cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On ajoute des nouveaux textes au jeu d'entrainement\n",
    "utterances_train += new_utterances_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "68fbf7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On ajoute des nouveaux textes au jeu de test\n",
    "utterances_test[\"LabeledTestSetUtterances\"] += new_utterances_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524445b3",
   "metadata": {},
   "source": [
    "## Enregistrement des datasets\n",
    "\n",
    "Nous allons enregistrer nos données au format JSON dans le Datastore :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b4b54db1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating arguments.\n",
      "Arguments validated.\n",
      "Uploading file to utterances/2022_01_02_13_47_28\n",
      "Uploading an estimated of 2 files\n",
      "Uploading /tmp/tmpthtrkpxe/utterances_test.json\n",
      "Uploaded /tmp/tmpthtrkpxe/utterances_test.json, 1 files out of an estimated total of 2\n",
      "Uploading /tmp/tmpthtrkpxe/utterances_train.json\n",
      "Uploaded /tmp/tmpthtrkpxe/utterances_train.json, 2 files out of an estimated total of 2\n",
      "Uploaded 2 files\n",
      "Creating new dataset\n"
     ]
    }
   ],
   "source": [
    "with tempfile.TemporaryDirectory() as tmp_dir_name:\n",
    "    # On enregistre les données\n",
    "    file_path = os.path.join(tmp_dir_name, \"utterances_train.json\")\n",
    "    with open(file_path, \"w\") as f:\n",
    "        json.dump(utterances_train, f)\n",
    "        \n",
    "    file_path = os.path.join(tmp_dir_name, \"utterances_test.json\")\n",
    "    with open(file_path, \"w\") as f:\n",
    "        json.dump(utterances_test, f)\n",
    "    \n",
    "    # On upload tous les fichiers dans le datastore\n",
    "    ds = Dataset.File.upload_directory(\n",
    "        tmp_dir_name,\n",
    "        target=(datastore, \"utterances/\" + datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")),\n",
    "        overwrite=True,\n",
    "        show_progress=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f51ef235",
   "metadata": {},
   "source": [
    "On crée ensuite un Dataset Azure à partir de ces fichiers :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c36f51a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds.register(\n",
    "    workspace=ws,\n",
    "    name=\"utterances\",\n",
    "    description=\"Train and test utterances\",\n",
    "    create_new_version=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "48e42cd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Création du dataset 'utterances' version 2.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Création du dataset '{ds.name}' version {ds.version}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11957709",
   "metadata": {},
   "source": [
    "# Enregistrement des paramètres de LUIS sur Github\n",
    "\n",
    "Il existe plusieurs façons de créer un modèle LUIS. Nous avons d'abord testé le tutorial suivant qui utilise le SDK Python : [quickstart](https://docs.microsoft.com/en-us/azure/cognitive-services/luis/client-libraries-rest-api?tabs=windows&pivots=programming-language-python).\n",
    "\n",
    "Nous nous sommes ensuite apperçut que l'on pouvait importer et exporter notre modèle au format JSON ([en savoir plus](https://docs.microsoft.com/en-us/azure/cognitive-services/luis/app-schema-definition)). Ce format s'avère pratique pour versionner le modèle et il reste assez simple pour être manipulé dans le cadre de recherche d'hyperparamètres. Cette méthode utilise le SDK python ainsi que l'API REST de LUIS. Les paramètres du modèle LUIS ainsi que les informations du jeu de données sont stockés dans le fichier `../P10_02_luis/params.json`. C'est ce fichier qui sera ensuite utilisé par les Github actions pour déployer le modèle en production."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c09f50",
   "metadata": {},
   "source": [
    "## Mise à jour des paramètres de LUIS\n",
    "\n",
    "On va donc commencer par mettre à jour le fichier JSON, notamment les informations du jeu de données précédemment créé."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "132dc998",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_params = params.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "385a0bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # En cas de modification du modèle LUIS, penser à incrémenter son numéro de version\n",
    "# new_model_version = float(model_version) + 0.1\n",
    "# new_model_version = f\"{new_model_version:0.1f}\"\n",
    "\n",
    "# new_params[\"model\"][\"versionId\"] = new_model_version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9fdae0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On met à jour les paramètres avec le jeu de données que l'on a créé\n",
    "new_params[\"dataset\"][\"name\"] = ds.name\n",
    "new_params[\"dataset\"][\"version\"] = ds.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "90316403",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On enregistre les nouveaux paramètres\n",
    "with open(\"../P10_02_luis/params.json\", \"w\") as f:\n",
    "    json.dump(new_params, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650cd4b9",
   "metadata": {},
   "source": [
    "## Evaluation du nouveau modèle\n",
    "\n",
    "Nous allons utiliser les mêmes briques logicielles que celles utilisées pour le déployement du modèle en production. Elles sont disponible dans le fichier `../P10_02_luis/utils.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9e200445",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On commence par créer un nom de version temporaire\n",
    "tmp_app_version = \"tmp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "036eb3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On crée ensuite une nouvelle version du modèle.\n",
    "# Un premier modèle a déjà été créé dans le script de création\n",
    "# des ressources de LUIS \"../P10_02_luis/luis_create.sh\".\n",
    "# Ce 1er modèle a été créé à partir du fichier \"../P10_02_luis/params.json\".\n",
    "create_new_version(env, tmp_app_version, new_params[\"model\"], utterances_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b43d275c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On entraine notre modèle\n",
    "train(env, tmp_app_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e4e3380b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On le déploie sur l'environnement de test\n",
    "deploy(env, tmp_app_version, \"staging\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "604e7d24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>model_type</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>book_flight</td>\n",
       "      <td>Intent Classifier</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>Intent Classifier</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>from_dt</td>\n",
       "      <td>Entity Extractor</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>to_dt</td>\n",
       "      <td>Entity Extractor</td>\n",
       "      <td>0.88</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>budget</td>\n",
       "      <td>Entity Extractor</td>\n",
       "      <td>0.88</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>from_city</td>\n",
       "      <td>Entity Extractor</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>to_city</td>\n",
       "      <td>Entity Extractor</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    model_name         model_type  precision  recall  f_score\n",
       "0  book_flight  Intent Classifier       0.92    1.00     0.96\n",
       "1         None  Intent Classifier       1.00    0.79     0.88\n",
       "2      from_dt   Entity Extractor       0.86    0.90     0.88\n",
       "3        to_dt   Entity Extractor       0.88    1.00     0.93\n",
       "4       budget   Entity Extractor       0.88    1.00     0.93\n",
       "5    from_city   Entity Extractor       0.57    0.85     0.69\n",
       "6      to_city   Entity Extractor       0.50    1.00     0.67"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# On évalue le modèle avec le jeu de test\n",
    "res = evaluate(env, is_staging=True, utterances=utterances_test)\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc27420",
   "metadata": {},
   "source": [
    "Pour chaque intent et chaque entity, on obtient 3 scores :\n",
    "- `precision` : parmis les labels prédit sur chaque mot, indique lesquels sont corrects.\n",
    "- `recall` : parmis les labels à détecter, indique lesquels ont été détéctés par le modèle.\n",
    "- `f_score` : moyenne harmonique de la precision et du recall.\n",
    "\n",
    "Pour un premier modèle, on obtient des scores satisfaisants.\n",
    "\n",
    "On remarque que le recall de l'intent `None` est à 0.78. Le modèle semble donc louper certain de ces intents.\n",
    "\n",
    "On s'apperçoit aussi que la precision des entités `from_city` et `to_city` sont à 0.57 et 0.5. Le modèle semble donc créer beaucoup de faux positifs sur ces entités."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "87a6f6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On supprime la version temporaire\n",
    "delete(env, tmp_app_version)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0aabf3",
   "metadata": {},
   "source": [
    "## Enregistrement du Github\n",
    "\n",
    "Commiter et pusher sur Github les modifications du fichier `../P10_02_luis/params.json`.\n",
    "\n",
    "Effectuer ensuite une demande de Pull request afin que ces nouveaux paramètres puissent êtres utilisés lors du déploiement du modèle."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p10",
   "language": "python",
   "name": "p10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "345px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
